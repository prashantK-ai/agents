{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "import os \n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatGroq(model = \"llama-3.2-1b-preview\",\n",
    "            groq_api_key = GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OData Query: $select=find&$filter=age\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# A simple mapping from common natural language phrases to OData query components\n",
    "NL_TO_OLQUERY_MAP = {\n",
    "    \"find\": \"select\",\n",
    "    \"filter\": \"filter\",\n",
    "    \"where\": \"filter\",\n",
    "    \"order by\": \"orderby\",\n",
    "    \"greater than\": \"gt\",\n",
    "    \"less than\": \"lt\",\n",
    "    \"equals\": \"eq\",\n",
    "    \"not equal\": \"ne\"\n",
    "}\n",
    "\n",
    "def parse_natural_language(query):\n",
    "    \"\"\"\n",
    "    Parse the natural language query to extract key information.\n",
    "    \"\"\"\n",
    "    doc = nlp(query.lower())\n",
    "    \n",
    "    # Placeholder for extracted parts of the OData query\n",
    "    select_part = []\n",
    "    filter_part = []\n",
    "    orderby_part = None\n",
    "    \n",
    "    # Parse each token and map to OData equivalent\n",
    "    for token in doc:\n",
    "        text = token.text\n",
    "        \n",
    "        if text in NL_TO_OLQUERY_MAP:\n",
    "            odata_term = NL_TO_OLQUERY_MAP[text]\n",
    "            \n",
    "            if odata_term == \"select\":\n",
    "                select_part.append(token.head.text)\n",
    "            elif odata_term == \"filter\":\n",
    "                filter_part.append(token.head.text)\n",
    "            elif odata_term in ('gt', 'lt', 'eq', 'ne'):\n",
    "                filter_part.append(f\"{token.head.text} {odata_term} {token.nbor().text}\")\n",
    "            elif odata_term == \"orderby\":\n",
    "                orderby_part = token.head.text\n",
    "        elif token.dep_ == \"ROOT\":\n",
    "            # Try to interpret the main intent (like finding/filtering)\n",
    "            if token.lemma_ == \"find\":\n",
    "                select_part.append(token.head.text)\n",
    "    \n",
    "    # Construct OData query\n",
    "    odata_query = construct_odata_query(select_part, filter_part, orderby_part)\n",
    "    return odata_query\n",
    "\n",
    "\n",
    "def construct_odata_query(select_part, filter_part, orderby_part):\n",
    "    \"\"\"\n",
    "    Construct the OData query from parsed components.\n",
    "    \"\"\"\n",
    "    odata_query = \"$select=\" + \",\".join(select_part)\n",
    "    \n",
    "    if filter_part:\n",
    "        odata_query += \"&$filter=\" + \" and \".join(filter_part)\n",
    "        \n",
    "    if orderby_part:\n",
    "        odata_query += \"&$orderby=\" + orderby_part\n",
    "    \n",
    "    return odata_query\n",
    "\n",
    "\n",
    "# Sample usage\n",
    "natural_language_query = \"Find customers where age greater than 30.\"\n",
    "odata_query = parse_natural_language(natural_language_query)\n",
    "print(\"OData Query:\", odata_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Natural Language to OData Mapping\n",
    "NL_TO_OLQUERY_MAP = {\n",
    "    \"find\": \"select\",\n",
    "    \"filter\": \"filter\",\n",
    "    \"where\": \"filter\",\n",
    "    \"order by\": \"orderby\",\n",
    "    \"greater than\": \"gt\",\n",
    "    \"less than\": \"lt\",\n",
    "    \"equals\": \"eq\",\n",
    "    \"not equal\": \"ne\"\n",
    "}\n",
    "\n",
    "def parse_natural_language(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Parse the natural language query to extract key information.\n",
    "    \"\"\"\n",
    "    doc = nlp(query.lower())\n",
    "    \n",
    "    # Placeholder for extracted parts of the OData query\n",
    "    select_part = []\n",
    "    filter_part = []\n",
    "    orderby_part = None\n",
    "    \n",
    "    # Parse each token and map to OData equivalent\n",
    "    for token in doc:\n",
    "        text = token.text\n",
    "        \n",
    "        if text in NL_TO_OLQUERY_MAP:\n",
    "            odata_term = NL_TO_OLQUERY_MAP[text]\n",
    "            \n",
    "            if odata_term == \"select\":\n",
    "                select_part.append(token.head.text)\n",
    "            elif odata_term == \"filter\":\n",
    "                filter_part.append(token.head.text)\n",
    "            elif odata_term == \"orderby\":\n",
    "                orderby_part = token.head.text\n",
    "        elif token.dep_ == \"ROOT\":\n",
    "            # Try to interpret the main intent (like finding/filtering)\n",
    "            if token.lemma_ == \"find\":\n",
    "                select_part.append(token.head.text)\n",
    "    \n",
    "    # Construct OData query\n",
    "    return construct_odata_query(select_part, filter_part, orderby_part)\n",
    "\n",
    "def construct_odata_query(select_part, filter_part, orderby_part):\n",
    "    \"\"\"\n",
    "    Construct the OData query from parsed components.\n",
    "    \"\"\"\n",
    "    odata_query = \"$select=\" + \",\".join(select_part)\n",
    "    \n",
    "    if filter_part:\n",
    "        odata_query += \"&$filter=\" + \" and \".join(filter_part)\n",
    "        \n",
    "    if orderby_part:\n",
    "        odata_query += \"&$orderby=\" + orderby_part\n",
    "    \n",
    "    return odata_query\n",
    "\n",
    "\n",
    "# Define the LangChain Tool\n",
    "def nl_to_odata_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    A LangChain tool that converts natural language queries into OData queries.\n",
    "    \"\"\"\n",
    "    odata_query = parse_natural_language(query)\n",
    "    return odata_query\n",
    "\n",
    "\n",
    "# Define the LangChain Tool object\n",
    "nl_to_odata_langchain_tool = Tool(\n",
    "    name=\"Natural Language to OData Converter\",\n",
    "    description=\"Converts natural language queries into OData query syntax.\",\n",
    "    func=nl_to_odata_tool\n",
    ")\n",
    "\n",
    "# Example Usage in a LangChain Agent (if needed)\n",
    "# from langchain.agents import initialize_agent, Tool, AgentType\n",
    "# from langchain.llms import OpenAI\n",
    "# \n",
    "# llm = OpenAI(temperature=0)  # Or your preferred LLM\n",
    "# tools = [nl_to_odata_langchain_tool]\n",
    "# \n",
    "# agent = initialize_agent(tools, llm, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
    "# agent.run(\"Find customers where age is greater than 30 and order by name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$select=find&$filter=age'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_1 = nl_to_odata_tool(\"Find customers where age greater than 30.\")\n",
    "d_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Natural Language to OData Mapping\n",
    "NL_TO_OLQUERY_MAP = {\n",
    "    \"find\": \"select\",\n",
    "    \"filter\": \"filter\",\n",
    "    \"where\": \"filter\",\n",
    "    \"order by\": \"orderby\",\n",
    "    \"greater than\": \"gt\",\n",
    "    \"less than\": \"lt\",\n",
    "    \"equals\": \"eq\",\n",
    "    \"not equal\": \"ne\"\n",
    "}\n",
    "\n",
    "def parse_natural_language(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Parse the natural language query to extract key information.\n",
    "    \"\"\"\n",
    "    blob = TextBlob(query.lower())\n",
    "    \n",
    "    # Placeholder for extracted parts of the OData query\n",
    "    select_part = []\n",
    "    filter_part = []\n",
    "    orderby_part = None\n",
    "    \n",
    "    # Parse each word and map to OData equivalent\n",
    "    words = blob.words\n",
    "    for i, word in enumerate(words):\n",
    "        if word in NL_TO_OLQUERY_MAP:\n",
    "            odata_term = NL_TO_OLQUERY_MAP[word]\n",
    "            \n",
    "            if odata_term == \"select\" and i < len(words) - 1:\n",
    "                select_part.append(words[i + 1])\n",
    "            elif odata_term == \"filter\" and i < len(words) - 1:\n",
    "                filter_part.append(f\"{words[i + 1]} {NL_TO_OLQUERY_MAP.get(words[i + 2], '')} {words[i + 3]}\")\n",
    "            elif odata_term == \"orderby\" and i < len(words) - 1:\n",
    "                orderby_part = words[i + 1]\n",
    "    \n",
    "    # Construct OData query\n",
    "    return construct_odata_query(select_part, filter_part, orderby_part)\n",
    "\n",
    "def construct_odata_query(select_part, filter_part, orderby_part):\n",
    "    \"\"\"\n",
    "    Construct the OData query from parsed components.\n",
    "    \"\"\"\n",
    "    odata_query = \"$select=\" + \",\".join(select_part)\n",
    "    \n",
    "    if filter_part:\n",
    "        odata_query += \"&$filter=\" + \" and \".join(filter_part)\n",
    "        \n",
    "    if orderby_part:\n",
    "        odata_query += \"&$orderby=\" + orderby_part\n",
    "    \n",
    "    return odata_query\n",
    "\n",
    "\n",
    "# Define the LangChain Tool\n",
    "def nl_to_odata_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    A LangChain tool that converts natural language queries into OData queries.\n",
    "    \"\"\"\n",
    "    odata_query = parse_natural_language(query)\n",
    "    return odata_query\n",
    "\n",
    "\n",
    "# Define the LangChain Tool object\n",
    "nl_to_odata_langchain_tool = Tool(\n",
    "    name=\"Natural Language to OData Converter\",\n",
    "    description=\"Converts natural language queries into OData query syntax.\",\n",
    "    func=nl_to_odata_tool\n",
    ")\n",
    "\n",
    "# Example Usage in a LangChain Agent (if needed)\n",
    "# from langchain.agents import initialize_agent, Tool, AgentType\n",
    "# from langchain.llms import OpenAI\n",
    "# \n",
    "# llm = OpenAI(temperature=0)  # Or your preferred LLM\n",
    "# tools = [nl_to_odata_langchain_tool]\n",
    "# \n",
    "# agent = initialize_agent(tools, llm, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
    "# agent.run(\"Find customers where age is greater than 30 and order by name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# A simple mapping from common natural language phrases to OData query components\n",
    "NL_TO_OLQUERY_MAP = {\n",
    "    \"find\": \"select\",\n",
    "    \"filter\": \"filter\",\n",
    "    \"where\": \"filter\",\n",
    "    \"order by\": \"orderby\",\n",
    "    \"greater than\": \"gt\",\n",
    "    \"less than\": \"lt\",\n",
    "    \"equals\": \"eq\",\n",
    "    \"not equal\": \"ne\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def parse_natural_language(query):\n",
    "    doc = nlp(query.lower())\n",
    "    \n",
    "    select_part = []\n",
    "    filter_part = []\n",
    "    orderby_part = None\n",
    "    \n",
    "    for token in doc:\n",
    "        text = token.text\n",
    "        \n",
    "        if text in NL_TO_OLQUERY_MAP:\n",
    "            odata_term = NL_TO_OLQUERY_MAP[text]\n",
    "            \n",
    "            if odata_term == \"select\":\n",
    "                select_part.append(token.head.text)\n",
    "            elif odata_term == \"filter\":\n",
    "                filter_part.append(token.head.text)\n",
    "            elif odata_term in (\"gt\", \"lt\", \"eq\", \"ne\"):\n",
    "                filter_part.append(f\"{token.head.text} {odata_term} {token.nbor().text}\")\n",
    "            elif odata_term == \"orderby\":\n",
    "                orderby_part = token.head.text\n",
    "        elif token.dep_ == \"ROOT\":\n",
    "            if token.lemma_ == \"find\":\n",
    "                select_part.append(token.head.text)\n",
    "    \n",
    "    odata_query = construct_odata_query(select_part, filter_part, orderby_part)\n",
    "    return odata_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Query: Find customers where age greater than 30\n",
      "OData Query: $select=customers&$filter=age gt 30\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# A mapping from common natural language phrases to OData query components\n",
    "NL_TO_OLQUERY_MAP = {\n",
    "    \"find\": \"select\",\n",
    "    \"get\": \"select\",\n",
    "    \"filter\": \"filter\",\n",
    "    \"where\": \"filter\",\n",
    "    \"order by\": \"orderby\",\n",
    "    \"greater than\": \"gt\",\n",
    "    \"less than\": \"lt\",\n",
    "    \"equals\": \"eq\",\n",
    "    \"not equal\": \"ne\",\n",
    "    \"equal to\": \"eq\"\n",
    "}\n",
    "\n",
    "def parse_natural_language(query):\n",
    "    \"\"\"\n",
    "    Parse the natural language query to extract key information.\n",
    "    \"\"\"\n",
    "    doc = nlp(query.lower())\n",
    "    \n",
    "    # Placeholder for extracted parts of the OData query\n",
    "    select_part = []\n",
    "    filter_part = []\n",
    "    orderby_part = None\n",
    "    \n",
    "    # Parse each token and map to OData equivalent\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.text == \"find\" or token.text == \"get\":\n",
    "            # The next token is likely what we're selecting\n",
    "            if i + 1 < len(doc):\n",
    "                select_part.append(doc[i+1].text)\n",
    "        elif token.text == \"where\":\n",
    "            # Look for the condition after \"where\"\n",
    "            if i + 3 < len(doc):\n",
    "                field = doc[i+1].text\n",
    "                condition = \" \".join([t.text for t in doc[i+2:i+4]])\n",
    "                if condition in NL_TO_OLQUERY_MAP:\n",
    "                    odata_condition = NL_TO_OLQUERY_MAP[condition]\n",
    "                    if i + 4 < len(doc):\n",
    "                        value = doc[i+4].text\n",
    "                        filter_part.append(f\"{field} {odata_condition} {value}\")\n",
    "    \n",
    "    # Construct OData query\n",
    "    odata_query = construct_odata_query(select_part, filter_part, orderby_part)\n",
    "    return odata_query\n",
    "\n",
    "def construct_odata_query(select_part, filter_part, orderby_part):\n",
    "    \"\"\"\n",
    "    Construct the OData query from parsed components.\n",
    "    \"\"\"\n",
    "    odata_query = \"$select=\" + \",\".join(select_part) if select_part else \"\"\n",
    "    \n",
    "    if filter_part:\n",
    "        odata_query += \"&$filter=\" + \" and \".join(filter_part)\n",
    "        \n",
    "    if orderby_part:\n",
    "        odata_query += \"&$orderby=\" + orderby_part\n",
    "    \n",
    "    return odata_query\n",
    "\n",
    "# Sample usage\n",
    "natural_language_query = \"Find customers where age greater than 30\"\n",
    "odata_query = parse_natural_language(natural_language_query)\n",
    "print(\"Natural Language Query:\", natural_language_query)\n",
    "print(\"OData Query:\", odata_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
